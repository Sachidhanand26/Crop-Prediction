# -*- coding: utf-8 -*-
"""Crop Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tlCTKDeRTKOKx9HYSIsTQiXIE9Z-j5Uh
"""

Objective: Develop a model which can recommend a crop for the soil based on predicting given paramenters

"""Step-1: Implement a model and train it using the dataset"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score
from sklearn.pipeline import make_pipeline

# Load the dataset
file_path = 'Crop_recommendation.csv'
df = pd.read_csv(file_path)

# Encode crop labels
crop_le = LabelEncoder()
df['label'] = crop_le.fit_transform(df['label'])

# Encode soil types
soil_le = LabelEncoder()
df['suitable_soil_type'] = soil_le.fit_transform(df['suitable_soil_type'])

# Split the data into features and target
X = df.drop('label', axis=1)
y = df['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Build a pipeline with scaling and a Random Forest Classifier
model = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))

# Train the model
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)

# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
auc = roc_auc_score(y_test, y_prob, multi_class='ovr')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

# Display performance metrics
print(f"Accuracy: {accuracy}")
print(f"F1 Score: {f1}")
print(f"AUC Score: {auc}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""Step-2: Save the model

After training the model, you can save it using Python's 'joblib' or 'pickle' libraries, so you don't have to train it again each time.
"""

import joblib

# Save the model and encoders
joblib.dump(model, 'crop_recommendation_model.pkl')
joblib.dump(crop_le, 'crop_label_encoder.pkl')
joblib.dump(soil_le, 'soil_label_encoder.pkl')

"""Step-3: Load the model
When you want to use the model, load it back from the file.
"""

import joblib
import pandas as pd

# Load the model and encoders
model = joblib.load('crop_recommendation_model.pkl')
crop_le = joblib.load('crop_label_encoder.pkl')
soil_le = joblib.load('soil_label_encoder.pkl')

"""Step-4: Create a dataframe with the data you want to predict."""

# Example new data
new_data = pd.DataFrame({
    'N': [90],
    'P': [42],
    'K': [43],
    'temperature': [20.879744],
    'humidity': [82.002744],
    'ph': [6.502985],
    'rainfall': [202.935536],
    'suitable_soil_type': [soil_le.transform(['Clayey'])[0]]
})

"""Step-5: Now make prediction by running the model."""

# Predict the crop
predicted_label = model.predict(new_data)
predicted_crop = crop_le.inverse_transform(predicted_label)

print(f"Recommended crop: {predicted_crop[0]}")

"""Step-6 (Optional): If you want the probabilities of each crop, you can use this step."""

# Get probability estimates for each class
probabilities = model.predict_proba(new_data)

# Display probabilities
print(f"Probabilities: {probabilities}")

"""Example workflow for predicting a new data"""

import pandas as pd
import joblib

# Load the model and encoders
model = joblib.load('crop_recommendation_model.pkl')
crop_le = joblib.load('crop_label_encoder.pkl')
soil_le = joblib.load('soil_label_encoder.pkl')

# Example new data
soil_type = 'Clayey'  # Example input

# Check if the soil type is valid
if soil_type not in soil_le.classes_:
    raise ValueError(f"Unknown soil type '{soil_type}'. Please choose from {list(soil_le.classes_)}.")

encoded_soil_type = soil_le.transform([soil_type])[0]

new_data = pd.DataFrame({
    'N': [90],
    'P': [42],
    'K': [43],
    'temperature': [20.879744],
    'humidity': [82.002744],
    'ph': [6.502985],
    'rainfall': [202.935536],
    'suitable_soil_type': [encoded_soil_type]
})

# Predict the crop
predicted_label = model.predict(new_data)
predicted_crop = crop_le.inverse_transform(predicted_label)

print(f"Recommended crop: {predicted_crop[0]}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score
from sklearn.pipeline import make_pipeline

# Load the dataset
file_path = 'Crop_recommendation.csv'
df = pd.read_csv(file_path)

# Encode crop labels
crop_le = LabelEncoder()
df['label'] = crop_le.fit_transform(df['label'])

# Encode soil types
soil_le = LabelEncoder()
df['suitable_soil_type'] = soil_le.fit_transform(df['suitable_soil_type'])

# Split the data into features and target
X = df.drop('label', axis=1)
y = df['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Build a pipeline with scaling and a Random Forest Classifier
model = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))

# Train the model
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)

# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
auc = roc_auc_score(y_test, y_prob, multi_class='ovr')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

# Display performance metrics
print(f"Accuracy: {accuracy}")
print(f"F1 Score: {f1}")
print(f"AUC Score: {auc}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

# User input for new data
print("\nEnter the following details for crop prediction:")

N = int(input("Nitrogen content (N): "))
P = int(input("Phosphorus content (P): "))
K = int(input("Potassium content (K): "))
temperature = float(input("Temperature (Â°C): "))
humidity = float(input("Humidity (%): "))
ph = float(input("pH: "))
rainfall = float(input("Rainfall (mm): "))

soil_type = input("Soil type (e.g., Clayey, Sandy, Loamy): ")
encoded_soil_type = soil_le.transform([soil_type])[0]

# Create a DataFrame for the new data
new_data = pd.DataFrame({
    'N': [N],
    'P': [P],
    'K': [K],
    'temperature': [temperature],
    'humidity': [humidity],
    'ph': [ph],
    'rainfall': [rainfall],
    'suitable_soil_type': [encoded_soil_type]
})

# Predict the crop
predicted_label = model.predict(new_data)
predicted_crop = crop_le.inverse_transform(predicted_label)

print(f"\nRecommended crop: {predicted_crop[0]}")